# M2. 활용 기술 익히기

## 2.1 Docker

### Docker

![](https://i.imgur.com/w1DCXpf.png)
- Docker는 **컨테이너 기반의 가상화 플랫폼**
- 기존 가상화는 OS 가상화를 수행함
	- 게스트 OS 전체를 가상화하기 때문에 높은 오버헤드가 발생하고 성능도 높지 않음
- 성능 문제를 해결하기 위해 프로세스를 격리하는 방식 등장
	- **컨테이너** 내에 프로세스를 격리
	- 여러 개의 컨테이너를 띄워도 성능 손실이 거의 없음
	- 이런 방법을 잘 정리하여 다양한 기능을 추가한 것이 바로 **Docker**

![](https://i.imgur.com/E4EumIn.png)
- Docker의 작동 방식은 간단함
	- Dockerfile에 Docker 이미지에 대한 명세를 자세하거 적기만 하면 됨
	- 이후 간단한 명령어로 이 이미지에 적힌 대로 컨테이너를 실행

> [!warning] 
> - Windows에서 WSL 없이 Docker를 사용하려면 Docker Desktop을 설치해야 함
> 	- Enterprise 용도로는 무료가 아니므로 주의할 것!

### Docker를 사용하는 이유

1. OS 독립성
	- Docker 컨테이너는 애플리케이션과 모든 종속성을 함께 패키징하여 **어떤 OS에서도** 동일한 환경을 제공할 수 있음
	- 개발 환경과 운영 환경이 다르더라도, 또는 모든 개발자가 다른 OS에서 개발하더라도 종속성 문제 없이 동일한 결과를 보장할 수 있음
2. 빠른 개발/배포 가능
	- Docker를 이용해 컨테이너를 빠르게 생성, 실행, 제거할 수 있기 때문에, ML 프로젝트의 **반복적인 작업이 단순화되고 가속화**됨
	- GitHub Actions, Jenkins와 같은 CI/CD 파이프라인과 결합하면 매우 간편하고 빠른 배포가 가능함
3. 높은 확장성과 유연성
	- 사용자가 많은 환경을 위해 개발/배포하는 경우 **Kubernetes와 같은 도구와 결합해 쉽게 확장하고 유연하게 배포**할 수 있음
	- 특히 운영 환경에서 사용량에 맞춰 컨테이너 수를 자동으로 조절하고, 부하에 따라 로드 밸런싱 구현도 용이함

### Dockerfile

- 원하는 Docker 이미지를 제작하기 위한 설정 파일
	- 이 파일만 있으면 Docker 이미지를 바로 빌드할 수 있음
- `<명령어> <인자>` 형태의 명령문으로만 구성되어 있음

- Dockerfile 문법
	- `FROM`
		- 생성할 이미지의 기본 이미지를 불러오는 명령어
	- `WORKDIR`
		- 컨테이너 내부에서의 작업 디렉토리를 전환하는 명렁어
	- `COPY/ADD`
		- 로컬 호스트의 파일이나 디렉터리를 컨테이너 내 파일 시스템으로 복사하거나 추가하기 위해 사용
	- `RUN`
		- 쉘(Shell)에서 명령을 입력하기 위한 명령어
	- `EXPOSE`
		- 컨테이너 내부에서 포트를 열어주는 명령어
		- 컨테이너 외부에서 접근하려면 `docker run -p <port>` 형식의 명령어를 실행해야 함
	- `USER`
		- 컨테이너에서 사용할 기본 사용자명
	- `CMD`
		- 컨테이너를 실행할 떄의 디폴트 커맨드나 파라미터
		- 컨테이너 실행 시 주어지는 인자에 덮어씌워질 수 있음
		- `ENTRYPOINT` 와 구분 필요
	- `ENV`
		- 컨테이너 내 환경 변수를 설정하기 위한 명령어
		- `ENV <key>=<value>` 형태로 사용
	- `ARG`
		- Docker 이미지를 빌드할 때 넘길 인자를 정의하는 명령어
		- `ARG <name>=<default value>` 형태로 사용

- Dockerfile 예시

```dockerfile
FROM python:3.12
WORKDIR /usr/local/app

# Install the application dependencies
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

# Copy in the source code
COPY src ./src
EXPOSE 5000

# Setup an app user so the container doesn't run as the root user
RUN useradd app
USER app

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
```

### Docker 기본 명령어

- `docker run`
	- `docker run hello-world`
- `docker stop`
	- 실행 중인 컨테이너를 중지하는 명령어
- `docker ps`
	- `hello-world` 컨테이너는 실행 후 바로 종료되기 때문에 목록에 나오지 않음
- `docker ps -a`
	- 종료된 컨테이너도 나오기 때문에 `hello-world`가 목록에 있음
- `docker images`
	- 실행한 컨테이너의 이미지가 목록에 나옴
- `docker rm`
	- 컨테이너 ID의 일부만 입력해도 삭제 가능
	- 반드시 컨테이너를 중지한 후에 수행
- `docker rmi`
	- 이미지 ID의 일부만 입력해도 삭제 가능
- `docker exec`
	- 컨테이너 내부의 명령어를 실행시켜야 할 때 활용

### Docker Compose

- 한 번에 여러 개의 컨테이너를 띄우려면 번거롭게 컨테이너 실행 명령어를 여러 번 수행하는 것보다 Docker Compose를 활용하는 것이 좋음
- `docker-compose.yml` 작성하여 해당 위치에서 `docker compose up` 명령어를 실행하면 됨


```yml
# db/docker-compose.yml

services:
  db:
    image: mariadb:10.8.2-rc-focal
    container_name: mariadb
    hostname: mariadb
    volumes:
      - ${PWD}/data:/tmp
      - ${PWD}/docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d
    restart: always
    ports:
      - "3306:3306"
    environment:
      MARIADB_ROOT_PASSWORD: root
    networks:
      mlops_network:
  adminer:
    image: adminer
    container_name: mariadb_adminer
    hostname: adminer
    restart: always
    ports:
      - "8089:8080"
    networks:
      mlops_network:
networks:
  mlops_network:
    name: mlops_network
    external: true
```

- Line 1 : `services` 
	- 컨테이너로 실행할 서비스 목록을 아래에 정의
- Line 2 : `db`
	- 서비스 이름
- Line 3
	- 사용할 이미지 이름
	- **기본 이미지 이름:버전** 형식으로 작성
- Line 4
	- 컨테이너 이름
- Line 6
	- 볼륨 마운트 설정
	- A:B 형태로 작성
	- 로컬 디렉토리인 A가 컨테이너 내부의 B 디렉토리로 마운트된다는 의미
- Line 9
	- 컨테이너 재시작 정책
- Line 10
	- 포트 매핑 설정
	- A:B 형태로 작성
	- 외부에서는 A 포트로 접근 가능
- Line 12
	- 환경 변수 설정
- Line 14
	- 네트워크 설정
	- 동일한 네트워크에 있는 다른 컨테이너에서 해당 컨테이너 접근 가능
- Line 25
	- 네트워크 설정
- Line 26
	- 네트워크 이름
- Line 28
	- 이미 존재하는 네트워크를 사용하도록 지정
	- 서비스 실행 전에 `docker network create <network_name>` 실행 필요

> [!note]
> - `mariadb` 이미지는 `docker-entrypoint-initdb.d` 폴더 내에 있는 `sql` 파일 등을 컨테이너 생성 시 같이 실행
> 	- 해당 폴더를 활용해서 컨테이너 실행 시 초기화되어야 하는 데이터베이스, 테이블을 생성할 수 있음
  

### Docker Compose로 mariaDB와 Adminer 컨테이너 띄우기

```bash
# db 폴더로 접근하여 컨테이너를 띄우면 됨
$ cd db

# 만약 네트워크를 생성하지 않았다면 생성 필요
$ docker network create mlops_network

# -d 옵션을 추가하여 백그라운드에서 실행되도록 함
$ docker compose up -d
```

> [!note]
> - `docker compose up` 명령어에서 `-d` 플래그는 `--detach` 를 의미함
> 	- **컨테이너를 백그라운드로 실행**하는 방법

- 컨테이너를 띄웠다면 Codespace의 포트 탭에서 8089번으로 Adminer 접근 가능


## 2.2 SQLAlchemy

### SQLAlchemy?

![](https://i.imgur.com/F55ivb0.png)

- Python에서 가장 널리 사용되는 ORM
	- ORM (Object Relational Mapping)
		- 애플리케이션과 데이터베이스를 연결할 때 **SQL 언어가 아닌 애플리케이션의 개발 언어로 데이터베이스를 접근**하도록 도와주는 도구
		- 개발 언어의 일관성과 가독성을 높여주는 장점을 갖고 있음

- SQLAlchemy 사용 시 주의점
	- Pandas와의 버전 호환성 주의
		- Pandas 1.X 버전과 SQLAlchemy 1.X.X 버전이 호환됨
		- Pandas 2.X 버전과 SQLAlchemy 2.X.X 버전이 호환됨
		- 이외 경우에는 일부 호환되나 주의가 필요함
	- 의존성 충돌 주의
		- Airflow의 최신 버전이더라도 SQLAlchemy 2.X.X 버전과 호환이 안됨
			- 백엔드는 **최대한 최신 버전의 SQLAlchemy를 사용**할 것  
			- Airflow 관련 프로젝트와 백엔드를 **다른 가상환경으로** 쓰면 됨

### SQLAlchemy 사용해서 데이터 불러오기

- SQLAlchemy만을 이용하여 데이터를 불러올 수도 있으나 **Pandas와 통합하여 데이터를 쉽게 불러올 수 있음**
- SQLAlchemy의 모든 동작은 기본적으로 다음 순서를 따름
	1. URL 또는 접속 정보를 이용하여 데이터베이스와 연결을 맺는 엔진을 생성 
		- `url = {dialect}+{driver}://{username}:{password}@{host}:{port}/{database}`
		- `create_engine` 메서드를 활용해서 엔진 생성
	2. 엔진에 `connect()` 메서드를 활용해 **Connection** **연결 객체를 통해 데이터베이스와 상호작용**

> [!note]
> - 위 내용대로 데이터베이스의 URL을 작성하면 아래와 같음
> - `url = "mysql+pymysql://root:root@localhost:3306/mlops"`
> 	- 같은 네트워크를 사용하는 컨테이너 내부에서는 `HOST_NAME="mariadb"`
> 	- 로컬과 같은 컨테이너 외부에서는 `HOST_NAME="localhost"`


```python
# Jupyter Notebook

import pandas as pd
from sqlalchemy import create_engine, text

url = "mysql+pymysql://root:root@localhost:3306/mlops"
engine = create_engine(url)

sql = """select *
from mlops.customer_info
"""

with engine.connect() as conn:  # Context Manager 사용 권장
	df = pd.read_sql(sql, con=conn.connection)
```

> [!tip]
> - SQLAlchemy 2.X 버전을 사용한다면 `con=conn.connection` 이 아닌 단순히 `con=conn` 으로 가능

## 2.3 Airflow

### Airflow란

- 배치 지향 워크플로우를 개발, 스케줄링, 모니터링하기 위한 오픈 소스 플랫폼
- Airflow 내 다양한 Python 프레임워크를 통해 원하는 대로 워크플로우를 구성할 수 있음
- 주요 용어
	- DAG (Directed Acyclic Graph)
		- Airflow의 핵심 개념으로 Task를 종속성과 관계로 정리해 어떻게 실행해야 하는지 정의한 것
		- 방향성이 있고 순환이 없는 그래프 형태
		- 각 DAG는 Python 코드로 작성하고 다양한 메타데이터로 정의함
	- Task
		- DAG는 하나 이상의 Task로 구성되며, DAG에서 실행하는 작업 단위
		- 일반적으로 Operator 클래스로 정의되고, DAG 객체에 포함됨

### Airflow 아키텍처

![](https://i.imgur.com/7FlEuRO.png)

- **DAG Directory**: 
	- DAG 파일을 보관하는 디렉토리
- **Metadata Database**: 
	- 모든 컴포넌트가 공유하는 메타데이터를 저장하는 데이터베이스
- **API Server**:
	- UI와 REST API를 제공하는 컴포넌트
	- 과거 Webserver의 역할을 하며, `airflow api-server` 명령어로 실행
- **Scheduler**:
	- DAG의 실행을 계획하고 Task를 Worker에게 전달하는 역할
- **DAG Processor**:
	- DAG 파일을 파싱하여 데이터베이스에 업데이트하는 역할을 하는 필수 컴포넌트
		- Airflow 3.X 버전에서 도입
	- `airflow dag-processor` 명령어로 별도 실행
- **Worker**
	- Scheduler로부터 받은 Task를 실제로 처리하는 컴포넌트
- **Executor**
	- Task의 실행 방법을 정의하며, `LocalExecutor`, `CeleryExecutor` 등 다양한 종류가 있음

### Airflow의 장점

- 코드 기반으로 Task를 정의하여 유연성과 재사용성을 높일 수 있음
- Task의 흐름을 시각적으로 쉽게 파악할 수 있고, 스케줄링을 통한 관리가 쉬움
- 다양한 Executor를 지원하여 다양한 방식의 Task 실행이 가능함
- 다양한 플러그인과 연동이 가능함

### Airflow 시작하기

#### 기본 설정

```shell
# Airflow가 기본적으로 사용하는 폴더 경로 설정
mkdir ~/airflow
export AIRFLOW_HOME=~/airflow

# Codespace 환경에서는 설정을 일부 바꿔줘야 함
airflow config list --defaults > "${AIRFLOW_HOME}/airflow.cfg"
code ${AIRFLOW_HOME}/airflow.cfg

# 다음 내용을 변경
# 1. default_timezone = utc 에서 Asia/Seoul 로 변경 
# 2. sql_alchemy_conn = mysql+pymysql://root:root@localhost:3306/airflow
```

- Airflow DB 마이그레이션
```shell
# 가상환경 내에서 실행 (source .venv/bin/activate 이후)
# Airflow 3.X 버전에선 `db init`이나 `db upgrade`가 아닌 `db migrate`를 사용
airflow db migrate
```

- Airflow JWT 설정
```shell
# JWT token 생성
openssl rand -base64 16

# Airflow 설정에 값 추가
code ${AIRFLOW_HOME}/airflow.cfg

# jwt_secret = "YOUR_JWT_SECRET_TOKEN"
# simple_auth_manager_all_admins = True
```

> [!warning]
> - 위 설정은 실습 편의 상 수행한 것으로 실제 환경에선 삼가야 함 

- Airflow 실행
```shell
# 개발/테스트 목적으로는 `standalone`을 사용할 수 있음
airflow standalone

# 프로덕션 환경에서는 다음처럼 각 컴포넌트를 개별 터미널에서 실행
# airflow api-server
# airflow scheduler
# airflow dag-processor
```


#### 프로젝트 폴더 심볼릭 링크 생성

```shell
mkdir -p ~/airflow/dags
ln -snf /workspaces/advanced-mlops/utils ~/airflow/dags/utils
ln -snf /workspaces/advanced-mlops/pipelines ~/airflow/dags/pipelines

ll ~/airflow/dags
```

#### Airflow 변수 관리

- Admin → Variables 에서 변수 추가
	- Key: `AIRFLOW_DAGS_PATH`
	- Val: `/workspaces/advanced-mlops`
- 설정 후 `airflow variables get AIRFLOW_DAGS_PATH` 로 확인 가능

> [!tip]
> - 다음 경고 메시지가 발생하는 경우가 있음
> 	```
> 	{secrets_masker.py:484} WARNING - Skipping masking for a secret as it's too short (<5 chars)
> 	```
> - 추가 설정을 통해서 해당 경고를 무시할 수 있음 
> 	```shell
> 	code ${AIRFLOW_HOME}/airflow.cfg
> 	# 아래 설정 변경
> 	# min_length_masked_secret = 1
>	 ```

### 간단한 DAG

```python
# pipelines/tutorial/first_dag.py

from datetime import datetime, timedelta
from textwrap import dedent

import pendulum
from airflow.providers.standard.operators.bash import BashOperator
from airflow.sdk import DAG

from utils.callbacks import failure_callback, success_callback

local_timezone = pendulum.timezone("Asia/Seoul")

with DAG(
    dag_id="simple_dag",
    default_args={
        "owner": "user",
        "depends_on_past": False,
        "email": "jaeyoon.han@lgcns.com",
        "email_on_failure": False,
        "email_on_retry": False,
        "retries": 1,
        "retry_delay": timedelta(minutes=5),
        "on_failure_callback": failure_callback,
        "on_success_callback": success_callback,
    },
    description="Simple airflow dag",
    schedule="0 15 * * *",
    start_date=datetime(2025, 3, 1, tzinfo=local_timezone),
    catchup=False,
    tags=set(["lgcns", "mlops"]),
) as dag:
    task1 = BashOperator(
        task_id="print_date",
        bash_command="date",
    )
    task2 = BashOperator(
        task_id="sleep",
        depends_on_past=False,
        bash_command="sleep 5",
        retries=3,
    )

    loop_command = dedent(
        """
        {% set kst_ds = data_interval_start.in_timezone('Asia/Seoul').to_date_string() %}
        {% for i in range(5) %}
            echo "ds = {{ kst_ds }}"
            echo "macros.ds_add(ds, {{ i }}) = {{ macros.ds_add(kst_ds, i) }}"
        {% endfor %}
        """
    )
    task3 = BashOperator(
        task_id="print_with_loop",
        bash_command=loop_command,
    )

    task1 >> [task2, task3]

```

- `kst_ds = data_interval_start.in_timezone('Asia/Seoul').to_date_string()`
	- Airflow는 모든 DAG를 UTC로 인식함
	- 강제로 KST로 바꾸는 작업 필요